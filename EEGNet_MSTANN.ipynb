{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMiDhMjpbsOfbKPYkibvcqy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Napomini/Individual_models/blob/main/EEGNet_MSTANN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EEG Signal Acquisition\n"
      ],
      "metadata": {
        "id": "aoFM77Ot-iyp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Downloading BCI Competition IV 2a Dataset\n"
      ],
      "metadata": {
        "id": "0sa_1TAf-w20"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.bbci.de/competition/download/competition_iv/BCICIV_2a_gdf.zip"
      ],
      "metadata": {
        "id": "AAF2pFuU_KM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/cleaned_data/"
      ],
      "metadata": {
        "id": "s_zn19fH_S0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!unzip /content/BCICIV_2a_gdf.zip -d raw_data"
      ],
      "metadata": {
        "id": "ifquRhIf_T9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Packages"
      ],
      "metadata": {
        "id": "ARMnDok8_Z_v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install mne"
      ],
      "metadata": {
        "id": "G7g5X2ZL_kPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install torch-summary"
      ],
      "metadata": {
        "id": "sQuQLn8u_lTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install captum"
      ],
      "metadata": {
        "id": "YD2TSsMv_oQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install --upgrade mne == 1.4.2 numpy == 1.23.5 --quite"
      ],
      "metadata": {
        "id": "53qBaix0_s41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install tensorflow==2.15.0"
      ],
      "metadata": {
        "id": "-Ta9tAuF_vAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.kill (os.getpid( ), 9)"
      ],
      "metadata": {
        "id": "bXkQ47wq_4aG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Libraries\n"
      ],
      "metadata": {
        "id": "Jbb935nQ_8le"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import mne\n",
        "import math\n",
        "import copy\n",
        "import gdown\n",
        "import random\n",
        "import scipy.io\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sn\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from captum.attr import DeepLift\n",
        "from tensorflow import keras\n",
        "\n",
        "\n",
        "# Torch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "\n",
        "# Scikit-Learn\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "asYdLJZVADfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building Dataset"
      ],
      "metadata": {
        "id": "oQ4SwtrvAIqK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/cleaned_data/first_session\n",
        "!mkdir -p /content/cleaned_data/second_session"
      ],
      "metadata": {
        "id": "IZGekak9AMPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# First Session"
      ],
      "metadata": {
        "id": "uXBRzZE8ATYe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Pre-processing"
      ],
      "metadata": {
        "id": "gaThDopmAaoG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data_folder = '/content/raw_data/'\n",
        "cleaned_data_folder = '/content/cleaned_data/first_session/'\n",
        "files = os.listdir(raw_data_folder)\n",
        "\n",
        "# Selecting files with suffix 'T.gdf'\n",
        "filtered_files = [file for file in files if file.endswith('T.gdf')]\n",
        "\n",
        "raw_list = []\n",
        "\n",
        "# Iterating through filtered files\n",
        "for file in filtered_files:\n",
        "    file_path = os.path.join(raw_data_folder, file)\n",
        "\n",
        "    # Reading raw data\n",
        "    raw = mne.io.read_raw_gdf(file_path, eog=['EOG-left', 'EOG-central', 'EOG-right'], preload=True)\n",
        "    # Droping EOG channels\n",
        "    raw.drop_channels(['EOG-left', 'EOG-central', 'EOG-right'])\n",
        "\n",
        "    # High Pass Filtering 4-40 Hz\n",
        "    raw.filter(l_freq=4, h_freq=40, method='iir')\n",
        "\n",
        "    # Notch filter for Removal of Line Voltage\n",
        "    raw.notch_filter(freqs=50)\n",
        "\n",
        "    # Saving the modified raw data to a file with .fif suffix\n",
        "    new_file_path = os.path.join(cleaned_data_folder, file[:-4] + '.fif')\n",
        "    raw.save(new_file_path, overwrite=True)\n",
        "    # Appending data to the list\n",
        "    raw_list.append(raw)\n",
        "\n",
        "final_raw = mne.concatenate_raws(raw_list)\n",
        "new_file_path = os.path.join(cleaned_data_folder, 'First_Session_Subjects.fif')\n",
        "final_raw.save(new_file_path, overwrite=True)"
      ],
      "metadata": {
        "id": "p_AII8jJAgB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "events = mne.events_from_annotations(final_raw)\n",
        "events[1]"
      ],
      "metadata": {
        "id": "w4bGrsP1AkSz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = mne.Epochs(final_raw, events[0], event_id=[7, 8, 9, 10], tmin=0, tmax=4, reject=None, baseline=None, preload=True)\n",
        "first_session_data = epochs.get_data(copy=True)\n",
        "first_session_labels = epochs.events[:,-1]"
      ],
      "metadata": {
        "id": "VFd4ZSmNAlE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"First_session_dataset shape:\",first_session_data.shape)"
      ],
      "metadata": {
        "id": "-Dxip56QAqpK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Second Session"
      ],
      "metadata": {
        "id": "lEZXem8XAwhO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace this with your actual shareable link\n",
        "shareable_link = 'https://drive.google.com/file/d/11Ke2Xta1kv2xu2Mybuu_X51zJYjQ-VFo/view?usp=drive_link'\n",
        "\n",
        "# Extract file ID from the shareable link\n",
        "file_id = shareable_link.split('/d/')[1].split('/view')[0]\n",
        "\n",
        "# Create the direct download link\n",
        "download_url = f'https://drive.google.com/uc?id={file_id}&export=download'\n",
        "\n",
        "# Specify the output file path\n",
        "output_file = 'true_labels.zip'\n",
        "\n",
        "# Download the file\n",
        "gdown.download(download_url, output_file, quiet=False)"
      ],
      "metadata": {
        "id": "0rvyW0wQA07A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!unzip /content/true_labels.zip -d second_session_labels"
      ],
      "metadata": {
        "id": "XEYC64I5A47O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data_folder = '/content/raw_data/'\n",
        "cleaned_data_folder = '/content/cleaned_data/second_session/'\n",
        "mat_folder = '/content/second_session_labels/'\n",
        "\n",
        "# Selecting files with suffix 'E.mat'\n",
        "mat_files = os.listdir(mat_folder)\n",
        "filtered_math_labels = [file for file in mat_files if file.endswith('E.mat')]\n",
        "\n",
        "# Selecting files with suffix 'E.gdf'\n",
        "files = os.listdir(raw_data_folder)\n",
        "filtered_files = [file for file in files if file.endswith('E.gdf')]\n",
        "\n",
        "raw_list = []\n",
        "second_session_labels = np.array([])\n",
        "# Iterating through filtered files\n",
        "for file in filtered_files:\n",
        "    file_path = os.path.join(raw_data_folder, file)\n",
        "\n",
        "    # Reading raw data\n",
        "    raw = mne.io.read_raw_gdf(file_path, eog=['EOG-left', 'EOG-central', 'EOG-right'], preload=True)\n",
        "    # Droping EOG channels\n",
        "    raw.drop_channels(['EOG-left', 'EOG-central', 'EOG-right'])\n",
        "\n",
        "    # High Pass Filtering 4-40 Hz\n",
        "    raw.filter(l_freq=4, h_freq=40, method='iir')\n",
        "\n",
        "    # Saving the modified raw data to a file with .fif suffix\n",
        "    new_file_path = os.path.join(cleaned_data_folder, file[:-4] + '.fif')\n",
        "    raw.save(new_file_path, overwrite=True)\n",
        "    # Appending data to t he list\n",
        "    raw_list.append(raw)\n",
        "\n",
        "    # Mat files for the labels\n",
        "    mat_file_name = file.replace('.gdf', '.mat')\n",
        "    mat_file_path = os.path.join(mat_folder, mat_file_name)\n",
        "    print(f\"data:{file}, label:{mat_file_name}\")\n",
        "\n",
        "    if os.path.exists(mat_file_path):\n",
        "        mat_data = scipy.io.loadmat(mat_file_path)\n",
        "        class_labels = mat_data.get('classlabel', [])\n",
        "\n",
        "        # Check if 'classlabel' key exists and is not empty\n",
        "        if class_labels.size > 0:\n",
        "             # Convert to a NumPy array and flatten\n",
        "            class_labels_array = np.array(class_labels, dtype=int).flatten()\n",
        "            # Concatenate with the existing test_labels array\n",
        "            second_session_labels = np.concatenate((second_session_labels, class_labels_array))\n",
        "        else:\n",
        "            print(f\"Warning: 'classlabel' not found or empty in {mat_file_name}.\")\n",
        "    else:\n",
        "        print(f\"Warning: {mat_file_name} not found.\")\n",
        "\n",
        "final_raw = mne.concatenate_raws(raw_list)\n",
        "new_file_path = os.path.join(cleaned_data_folder, 'Second_Session_Subjects.fif')\n",
        "final_raw.save(new_file_path, overwrite=True)"
      ],
      "metadata": {
        "id": "yxoRPxm0A7kq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "events = mne.events_from_annotations(final_raw)\n",
        "events[1]"
      ],
      "metadata": {
        "id": "TLFecSsyA9-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = mne.Epochs(final_raw, events[0], event_id=7, tmin=0, tmax=4, reject=None, baseline=None, preload=None)\n",
        "second_session_data = epochs.get_data(copy=True)"
      ],
      "metadata": {
        "id": "unR9YNFpBAvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Second Session Dataset shape:\",second_session_data.shape)"
      ],
      "metadata": {
        "id": "ixvhrrJCBC6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Structuring Data"
      ],
      "metadata": {
        "id": "nJM8M0rKBFYi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choosing Device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Loss Function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Normalizing Labels to [0, 1, 2, 3]\n",
        "y_train = first_session_labels - np.min(first_session_labels)\n",
        "y_test = second_session_labels - np.min(second_session_labels)\n",
        "\n",
        "# Normalizing Input features: z-score(mean=0, std=1)\n",
        "X_first_session = (first_session_data - np.mean(first_session_data)) / np.std(first_session_data)\n",
        "X_second_session = (second_session_data - np.mean(second_session_data)) / np.std(second_session_data)\n",
        "\n",
        "X = np.concatenate((X_first_session, X_second_session))\n",
        "y = np.concatenate((y_train, y_test))\n",
        "\n",
        "# Spliting  Data: 90% for Train and 10% for Test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42, stratify=y)\n",
        "\n",
        "# Converting to Tensor\n",
        "X_train = torch.Tensor(X_train).unsqueeze(1).to(device)\n",
        "X_test = torch.Tensor(X_test).unsqueeze(1).to(device)\n",
        "y_train = torch.LongTensor(y_train).to(device)\n",
        "y_test = torch.LongTensor(y_test).to(device)\n",
        "\n",
        "# Creating Tensor Dataset\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "\n",
        "# Printing the sizes\n",
        "print(\"Size of X_train:\", X_train.size())\n",
        "print(\"Size of X_test:\", X_test.size())\n",
        "print(\"Size of y_train:\", y_train.size())\n",
        "print(\"Size of y_test:\", y_test.size())"
      ],
      "metadata": {
        "id": "DyO-T5RmBO7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Class Training"
      ],
      "metadata": {
        "id": "jDDEpW0JBVda"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TrainModel():\n",
        "    def __init__(self,):\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    def train_model(self, model, train_dataset, learning_rate=0.001, batch_size=64, epochs=500):\n",
        "        model = model.to(self.device)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "        highest_train_accuracy = 0.0\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            model.train()\n",
        "            running_loss = 0.0\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            for inputs, labels in train_loader:\n",
        "                inputs = inputs.to(self.device)\n",
        "                labels = labels.to(self.device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                outputs, _ = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "            epoch_loss = running_loss / len(train_loader.dataset)\n",
        "            epoch_accuracy = correct / total\n",
        "            if epoch_accuracy > highest_train_accuracy:\n",
        "                highest_train_accuracy = epoch_accuracy\n",
        "            print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}, Accuracy: {(epoch_accuracy*100):.2f}%\")\n",
        "\n",
        "        average_loss = running_loss / len(train_loader.dataset)\n",
        "        print(\"Average Loss:\", average_loss)\n",
        "        print(f\"Highest Train Accuracy:{(highest_train_accuracy*100):.2f}\")\n",
        "\n",
        "        # Saving model\n",
        "        torch.save(model.state_dict(), 'eegnet_model.pth')\n",
        "        return model"
      ],
      "metadata": {
        "id": "GP6R4-f9BZ5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluating Model"
      ],
      "metadata": {
        "id": "OY0NuDmUBe6w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EvalModel():\n",
        "    def __init__(self, model):\n",
        "        self.model = model.to(device)\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    def test_model(self, test_dataset):\n",
        "        self.model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in test_loader:\n",
        "                inputs = inputs.to(self.device)\n",
        "                labels = labels.to(self.device)\n",
        "                outputs, _ = self.model(inputs)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        accuracy = (correct / total) * 100\n",
        "        print(\"/------------------------------/\")\n",
        "        print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
        "        print(\"/------------------------------/\")\n",
        "        return accuracy\n",
        "\n",
        "    def plot_confusion_matrix(self, test_dataset, classes):\n",
        "        self.model.eval()\n",
        "        y_pred = []\n",
        "        y_true = []\n",
        "        test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in test_loader:\n",
        "                inputs = inputs.to(self.device)\n",
        "                labels = labels.to(self.device)\n",
        "                outputs, _ = self.model(inputs)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                y_pred.append(predicted.item())\n",
        "                y_true.append(labels.item())\n",
        "\n",
        "        cf_matrix = confusion_matrix(y_true, y_pred)\n",
        "        cf_matrix = cf_matrix.astype('float') / cf_matrix.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "        df_cm = pd.DataFrame(cf_matrix, index=classes, columns=classes)\n",
        "\n",
        "        plt.figure(figsize=(10, 7))\n",
        "        sn.heatmap(df_cm, annot=True, cmap='Blues', fmt='.2f')\n",
        "        plt.xlabel('Predicted labels')\n",
        "        plt.ylabel('True labels')\n",
        "        plt.title('Confusion Matrix')\n",
        "        plt.savefig('confusion_matrix_model.png')\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "93-v-qgvBmp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EEGNet Model"
      ],
      "metadata": {
        "id": "R61C51d0Bs49"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EEGNetModel(nn.Module): # EEGNET-8,2\n",
        "    def __init__(self, chans=22, classes=4, time_points=1001, temp_kernel=32,\n",
        "                 f1=16, f2=32, d=2, pk1=8, pk2=16, dropout_rate=0.5, max_norm1=1, max_norm2=0.25):\n",
        "        super(EEGNetModel, self).__init__()\n",
        "        # Calculating FC input features\n",
        "        linear_size = (time_points//(pk1*pk2))*f2\n",
        "\n",
        "        # Temporal Filters\n",
        "        self.block1 = nn.Sequential(\n",
        "            nn.Conv2d(1, f1, (1, temp_kernel), padding='same', bias=False),\n",
        "            nn.BatchNorm2d(f1),\n",
        "        )\n",
        "        # Spatial Filters\n",
        "        self.block2 = nn.Sequential(\n",
        "            nn.Conv2d(f1, d * f1, (chans, 1), groups=f1, bias=False), # Depthwise Conv\n",
        "            nn.BatchNorm2d(d * f1),\n",
        "            nn.ELU(),\n",
        "            nn.AvgPool2d((1, pk1)),\n",
        "            nn.Dropout(dropout_rate)\n",
        "        )\n",
        "        self.block3 = nn.Sequential(\n",
        "            nn.Conv2d(d * f1, f2, (1, 16),  groups=f2, bias=False, padding='same'), # Separable Conv\n",
        "            nn.Conv2d(f2, f2, kernel_size=1, bias=False), # Pointwise Conv\n",
        "            nn.BatchNorm2d(f2),\n",
        "            nn.ELU(),\n",
        "            nn.AvgPool2d((1, pk2)),\n",
        "            nn.Dropout(dropout_rate)\n",
        "        )\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc = nn.Linear(linear_size, classes)\n",
        "\n",
        "        # Apply max_norm constraint to the depthwise layer in block2\n",
        "        self._apply_max_norm(self.block2[0], max_norm1)\n",
        "\n",
        "        # Apply max_norm constraint to the linear layer\n",
        "        self._apply_max_norm(self.fc, max_norm2)\n",
        "\n",
        "    def _apply_max_norm(self, layer, max_norm):\n",
        "        for name, param in layer.named_parameters():\n",
        "            if 'weight' in name:\n",
        "                param.data = torch.renorm(param.data, p=2, dim=0, maxnorm=max_norm)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.block1(x)\n",
        "        temporal_features = x\n",
        "        x = self.block2(x)\n",
        "        spatial_features1 = x\n",
        "        x = self.block3(x)\n",
        "        spatial_features2 = x\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc(x)\n",
        "        return x, [temporal_features, spatial_features1, spatial_features2]"
      ],
      "metadata": {
        "id": "SU66EybsBynr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Summary"
      ],
      "metadata": {
        "id": "DR0AGv1rB30x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = (1, 22, 1001)\n",
        "eegnet_model = EEGNetModel().to(device)\n",
        "summary(eegnet_model, input_size)"
      ],
      "metadata": {
        "id": "p_pkAop9B8Le"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Model"
      ],
      "metadata": {
        "id": "NHnZF5tCB_D3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eegnet_model = EEGNetModel().to(device)\n",
        "\n",
        "# Training Hyperparameters\n",
        "EPOCHS = 500\n",
        "BATCH_SIZE = 64\n",
        "LEARNING_RATE = 0.001\n",
        "trainer = TrainModel()\n",
        "trained_eegnet_model = trainer.train_model(eegnet_model, train_dataset, learning_rate=LEARNING_RATE,\n",
        "                                   batch_size=BATCH_SIZE, epochs=EPOCHS)\n",
        "torch.save(trained_eegnet_model.state_dict(), 'eegnet_model.pth')"
      ],
      "metadata": {
        "id": "1XM4w9x0CE0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluating Model (Confusion Matrix)"
      ],
      "metadata": {
        "id": "1c4NkUWxCMO8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classes_list = ['Left', 'Right', 'Foot', 'Tongue']\n",
        "eval_model = EvalModel(trained_eegnet_model)\n",
        "test_accuracy = eval_model.test_model(test_dataset)\n",
        "eval_model.plot_confusion_matrix(test_dataset, classes_list)"
      ],
      "metadata": {
        "id": "wbCnAb_gCX30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MSTANN Model"
      ],
      "metadata": {
        "id": "zr4KZjDHCm6I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MSM(nn.Module): # Multi-Scale Module\n",
        "    def __init__(self, chans=22, time_points=1001, f1=36, f2=54, f3=108, f4=216):\n",
        "        super(MSM, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(chans, f1, kernel_size=3, padding='same')\n",
        "        self.conv2 = nn.Conv1d(chans, f1, kernel_size=11, padding='same')\n",
        "        self.conv3 = nn.Conv1d(chans, f1, kernel_size=19, padding='same')\n",
        "        self.conv4 = nn.Conv1d(f3, f2, kernel_size=1, padding='same')\n",
        "        self.conv5 = nn.Conv1d(f4, f3, kernel_size=1, padding='same')\n",
        "        self.mp1 = nn.MaxPool1d(kernel_size=7, stride=2, padding=3)\n",
        "        self.mp2 = nn.MaxPool1d(kernel_size=19, stride=2, padding=9)\n",
        "        self.mp3 = nn.MaxPool1d(kernel_size=31, stride=2, padding=15)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Parallel Convs\n",
        "        conv1_out = self.conv1(x)\n",
        "        temporal_features1 = conv1_out\n",
        "        conv2_out = self.conv2(x)\n",
        "        temporal_features2 = conv2_out\n",
        "        conv3_out = self.conv3(x)\n",
        "        temporal_features3 = conv3_out\n",
        "        convs_cat = torch.cat([conv1_out, conv2_out, conv3_out], dim=1)\n",
        "        convs_cat_t = torch.cat([conv1_out, conv2_out, conv3_out], dim=1).permute(0,2,1)\n",
        "        temporal_features_cat1 = convs_cat_t\n",
        "        # Max Poolings\n",
        "        mp1 = self.mp1(convs_cat_t).permute(0,2,1)\n",
        "        mp2 = self.mp2(convs_cat_t).permute(0,2,1)\n",
        "        mp3 = self.mp3(convs_cat_t).permute(0,2,1)\n",
        "        # Second Concat\n",
        "        conv4_out = self.conv4(convs_cat)\n",
        "        temporal_features4 = conv4_out\n",
        "        convs_cat2 = torch.cat([mp1, mp2, mp3, conv4_out], dim=1)\n",
        "        temporal_features_cat2 = convs_cat2\n",
        "        out = self.conv5(convs_cat2)\n",
        "        temporal_features_total = out\n",
        "        temporal_features = [temporal_features1, temporal_features2, temporal_features3,\n",
        "                            temporal_features4, temporal_features_cat1, temporal_features_cat2,\n",
        "                            temporal_features_total]\n",
        "        return out, temporal_features\n",
        "class ResidualModule(nn.Module):\n",
        "    def __init__(self, f1=108, f2=54):\n",
        "        super(ResidualModule, self).__init__()\n",
        "\n",
        "        self.block1 = nn.Sequential(\n",
        "            nn.Conv1d(f1, f2, kernel_size=1, padding=0), # Conv6\n",
        "            nn.BatchNorm1d(f2),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.block2 = nn.Sequential(\n",
        "            nn.Conv1d(f2, f1, kernel_size=3, padding=1), # Conv7\n",
        "            nn.BatchNorm1d(f1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.block3 = nn.Sequential(\n",
        "            nn.Conv1d(f1, f2, kernel_size=1, padding=0), # Conv8\n",
        "            nn.BatchNorm1d(f2),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.block4 = nn.Sequential(\n",
        "            nn.Conv1d(f2, f1, kernel_size=3, padding=1), # Conv9\n",
        "            nn.BatchNorm1d(f1),\n",
        "        )\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        # Sequential Convs\n",
        "        x = self.block1(x)  # Conv6\n",
        "        x = self.block2(x)  # Conv7\n",
        "        x = self.block3(x)  # Conv8\n",
        "        x = self.block4(x)  # Conv9\n",
        "\n",
        "        # Residual Connection\n",
        "        x += residual\n",
        "        x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "class CTAM(nn.Module):\n",
        "    def __init__(self, f1=216, linear_size=108, time_points=1001):\n",
        "        super(CTAM, self).__init__()\n",
        "        # Channel Attention Module(CAM)\n",
        "        self.cam_maxpool = nn.Sequential(\n",
        "            nn.MaxPool1d(kernel_size=1),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(linear_size*time_points, linear_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(linear_size, linear_size),\n",
        "        )\n",
        "        self.cam_avgpool = nn.Sequential(\n",
        "            nn.AvgPool1d(kernel_size=1),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(linear_size*time_points, linear_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(linear_size, linear_size),\n",
        "        )\n",
        "\n",
        "        # Temporal Attention Module(TAM)\n",
        "        self.tam_maxpool = nn.MaxPool1d(kernel_size=1)\n",
        "        self.tam_avgpool = nn.AvgPool1d(kernel_size=1)\n",
        "        self.tam_conv = nn.Conv1d(f1, 1, kernel_size=7, padding=3)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # CAM operations\n",
        "        cam_maxpool_out = self.cam_maxpool(x)\n",
        "        cam_avgpool_out = self.cam_avgpool(x)\n",
        "        cam_pool_out = self.sigmoid(cam_maxpool_out + cam_avgpool_out).unsqueeze(2)\n",
        "        cam_out = x * cam_pool_out\n",
        "        # TAM operations\n",
        "        tam_maxpool_out = self.tam_maxpool(cam_out)\n",
        "        tam_avgpool_out = self.tam_avgpool(cam_out)\n",
        "        tam_cat = torch.cat((tam_avgpool_out, tam_maxpool_out), dim=1)\n",
        "        tam_conv_out = self.tam_conv(tam_cat)\n",
        "        tam_out = self.sigmoid(tam_conv_out)\n",
        "        tam_out_expanded = tam_out.expand(-1, 108, -1)\n",
        "        ctam_out = tam_out_expanded * cam_out\n",
        "        return ctam_out\n",
        "\n",
        "\n",
        "class MSCTANNModel(nn.Module):\n",
        "    def __init__(self, chans=22, f1=36, f2=54, f3=108, f4=216,\n",
        "                 classes=4, time_points=1001, dropout_rate=0.4):\n",
        "        super(MSCTANNModel, self).__init__()\n",
        "        linear_size = f3*time_points\n",
        "        self.classes = classes\n",
        "        self.msm = MSM(chans=chans,time_points=time_points, f1=f1, f2=f2, f3=f3, f4=f4)\n",
        "        self.residual_module = ResidualModule(f1=f3, f2=f2)\n",
        "        self.ctam = CTAM(f1=f4, linear_size=f3, time_points=time_points)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.fc = nn.Linear(linear_size, classes)\n",
        "    def forward(self, x):\n",
        "        x = x.squeeze(1) # Reducing Input dim from 4 to 3\n",
        "        x, temporal_features = self.msm(x)\n",
        "        x = self.residual_module(x)\n",
        "        x = self.ctam(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc(x)\n",
        "        x = self.dropout(x)\n",
        "        return x, temporal_features"
      ],
      "metadata": {
        "id": "7L7MTDaECs-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Summary"
      ],
      "metadata": {
        "id": "Xp7llEvtCyiP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = (1, 22, 1001)\n",
        "msctaan_model = MSCTANNModel().to(device)\n",
        "summary(msctaan_model, input_size)"
      ],
      "metadata": {
        "id": "KeW9FazVC1_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Model"
      ],
      "metadata": {
        "id": "p3ZCvUaiC3n1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "msctaan_model = MSCTANNModel().to(device)\n",
        "\n",
        "# Training Hyperparameters\n",
        "EPOCHS = 500\n",
        "BATCH_SIZE = 64\n",
        "LEARNING_RATE = 0.001\n",
        "trainer = TrainModel()\n",
        "trained_msctaan_model = trainer.train_model(msctaan_model, train_dataset, learning_rate=LEARNING_RATE,\n",
        "                                   batch_size=BATCH_SIZE, epochs=EPOCHS)\n",
        "torch.save(trained_msctaan_model.state_dict(), 'msctaan_model.pth')"
      ],
      "metadata": {
        "id": "G0Xrd4KNC-aM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluating Model (Confusion Matrix)"
      ],
      "metadata": {
        "id": "7iyPNtFrDBFI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classes_list = ['Left', 'Right', 'Foot', 'Tongue']\n",
        "eval_model = EvalModel(trained_msctaan_model)\n",
        "test_accuracy = eval_model.test_model(test_dataset)\n",
        "eval_model.plot_confusion_matrix(test_dataset, classes_list)"
      ],
      "metadata": {
        "id": "2DcqIER_DE-b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}